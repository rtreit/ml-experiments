{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8786ecf5",
   "metadata": {},
   "source": [
    "# Multi-target Regression Model\n",
    "\n",
    "Example of training a regression model to predict 3 target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725b4b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hvplot.pandas\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.4f\" % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b2b451",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd9308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b0ef32",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2641027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c447500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9f323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d28971",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df.iloc[:, :8]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8763b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 20))\n",
    "corrMatrix = df.iloc[:, :30].corr()\n",
    "sns.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf400cd6",
   "metadata": {},
   "source": [
    "# Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f8f527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop target columns\n",
    "target_columns = [\"target_a\", \"target_b\", \"target_c\"]\n",
    "X = df.drop(target_columns, axis=1)\n",
    "y = df[target_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa300df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a7232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf8a36c",
   "metadata": {},
   "source": [
    "1). X_train - This includes your all independent variables, these will be used to train the model, also as we have specified the test_size = 0.2, this means 80% of observations from your complete data will be used to train/fit the model and rest 20% will be used to test the model.\n",
    "\n",
    "2). X_test - This is remaining 20% portion of the independent variables from the data which will not be used in the training phase and will be used to make predictions to test the accuracy of the model.\n",
    "\n",
    "3). y_train - This is your dependent variable which needs to be predicted by this model, this includes category labels against your independent variables, we need to specify our dependent variable while training/fitting the model.\n",
    "\n",
    "4). y_test - This data has category labels for your test data, these labels will be used to test the accuracy between actual and predicted categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da8d606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb849191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def cross_val(model):\n",
    "    pred = cross_val_score(model, X, y, cv=10)\n",
    "    return pred.mean()\n",
    "\n",
    "\n",
    "def print_evaluate(true, predicted):\n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    print(\"MAE:\", mae)\n",
    "    print(\"MSE:\", mse)\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"R2 Square\", r2_square)\n",
    "    print(\"__________________________________\")\n",
    "\n",
    "\n",
    "def evaluate(true, predicted):\n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    return mae, mse, rmse, r2_square\n",
    "\n",
    "\n",
    "def evaluate_model(pipeline, X_test, y_test):\n",
    "    mod_name = str(pipeline.get_params()[\"multioutputregressor__estimator\"]).split(\"(\")[\n",
    "        0\n",
    "    ]\n",
    "    print(f\"Starting {mod_name}...\")\n",
    "    pred = pipeline.predict(X_test)\n",
    "    actual = y_test.reset_index(drop=True)\n",
    "    actual.columns = [\n",
    "        f\"act_{target_columns[0]}\",\n",
    "        f\"act_{target_columns[1]}\",\n",
    "        f\"act_{target_columns[2]}\",\n",
    "    ]\n",
    "    act_df = actual\n",
    "    pred_df = pd.DataFrame(\n",
    "        pred,\n",
    "        columns=[\n",
    "            f\"pred_{target_columns[0]}\",\n",
    "            f\"pred_{target_columns[1]}\",\n",
    "            f\"pred_{target_columns[2]}\",\n",
    "        ],\n",
    "    )\n",
    "    combined = pd.concat([act_df, pred_df], axis=1, join=\"inner\")\n",
    "    # print_evaluate(combined[\"act_dist\"], combined[\"pred_dist\"])\n",
    "    # print_evaluate(combined[\"act_ah\"], combined[\"pred_ah\"])\n",
    "    # print_evaluate(combined[\"act_av\"], combined[\"pred_av\"])\n",
    "    results_df = pd.DataFrame(\n",
    "        data=[\n",
    "            [\n",
    "                mod_name,\n",
    "                evaluate(\n",
    "                    combined[f\"act_{target_columns[0]}\"],\n",
    "                    combined[f\"pred_{target_columns[0]}\"],\n",
    "                )[3],\n",
    "                evaluate(\n",
    "                    combined[f\"act_{target_columns[1]}\"],\n",
    "                    combined[f\"pred_{target_columns[1]}\"],\n",
    "                )[3],\n",
    "                evaluate(\n",
    "                    combined[f\"act_{target_columns[2]}\"],\n",
    "                    combined[f\"pred_{target_columns[2]}\"],\n",
    "                )[3],\n",
    "            ]\n",
    "        ],\n",
    "        columns=[\n",
    "            \"Model\",\n",
    "            f\"R2_{target_columns[0]}\",\n",
    "            f\"R2_{target_columns[1]}\",\n",
    "            f\"R2_{target_columns[2]}\",\n",
    "        ],\n",
    "    )\n",
    "    results_df[\"Model\"] = results_df.apply(\n",
    "        lambda x: \"CatBoostRegressor\"\n",
    "        if x[\"Model\"].find(\"catboost\") != -1\n",
    "        else x[\"Model\"],\n",
    "        axis=1,\n",
    "    )\n",
    "    return combined, results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c6a077",
   "metadata": {},
   "source": [
    "# Scale the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6627264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([(\"std_scalar\", StandardScaler())])\n",
    "\n",
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_test = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f127ab1c",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2924a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "algs = [\n",
    "    LinearRegression,\n",
    "    XGBRegressor,\n",
    "    SVR,\n",
    "    LGBMRegressor,\n",
    "    BayesianRidge,\n",
    "    KernelRidge,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    "    CatBoostRegressor,\n",
    "    ElasticNet,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c6c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = []\n",
    "eval_results = []\n",
    "for alg in algs:\n",
    "    pipe = make_pipeline(MultiOutputRegressor(alg()))\n",
    "    pipe.fit(X_train, y_train)\n",
    "    model_eval = evaluate_model(pipe, X_test, y_test)\n",
    "    combined_df.append(model_eval[0])\n",
    "    eval_results.append(model_eval[1])\n",
    "\n",
    "result_df = pd.concat(eval_results, ignore_index=True)\n",
    "result_df[\"Mean\"] = (\n",
    "    result_df[f\"R2_{target_columns[0]}\"]\n",
    "    + result_df[f\"R2_{target_columns[1]}\"]\n",
    "    + result_df[f\"R2_{target_columns[2]}\"]\n",
    ") / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8221c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.sort_values(by=[\"Mean\"], ascending=False).reset_index(\n",
    "    drop=True\n",
    ").style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27094c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined_df[8]\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"True Values\": combined[f\"act_{target_columns[0]}\"],\n",
    "        \"Predicted Values\": combined[f\"pred_{target_columns[0]}\"],\n",
    "    }\n",
    ").hvplot.scatter(x=\"True Values\", y=\"Predicted Values\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
